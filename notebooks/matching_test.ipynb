{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7d6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, 'C:/Users/nconroy/Documents/EventClustering/POC/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbe0ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import corpus\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cb8cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 20)\n",
    "pd.set_option('display.max_colwidth', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c8a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile = \"data/new_articles.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f404d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(testfile, 'r') as read_obj:\n",
    "        # pass the file object to DictReader() to get the DictReader object\n",
    "        dict_reader = csv.DictReader(read_obj)\n",
    "        # get a list of dictionaries from dct_reader\n",
    "        flat_test = list(dict_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0429a47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'eng'\n",
    "basedataset = corpus.Corpus()\n",
    "basedataset.load_corpora(r\"../news-clustering/dataset/dataset.dev.json\",\n",
    "                          r\"../news-clustering/dataset/clustering.dev.json\", set([lang]))\n",
    "#basedataset.load_corpora(r\"../news-clustering/dataset/dataset.test.json\",\n",
    "#                           r\"../news-clustering/dataset/clustering.test.json\", set([lang]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8748f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_data = flat_test\n",
    "input_data = basedataset.documents \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e19d1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (input_data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c323d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stest_cluster_pool= pd.read_pickle(\"models/aggregator_testTHR_dev.pkl\")\n",
    "test_cluster_pool= pd.read_pickle(\"models/aggregator_NNent_dev.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f823fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_scores= utils.pd.read_pickle(\"models/scores_testTHR_dev.pkl\")\n",
    "test_scores= pd.read_pickle(\"models/scores_NNent_dev.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b504051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_times = utils.pd.read_pickle(\"models/timesNN.pkl\")\n",
    "test_times = pd.read_pickle(\"models/times_NNent_dev.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f45e48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (len(cluster_pool))\n",
    "print (len(test_cluster_pool.clusterpool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdedbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(cluster_pool):\n",
    "    for cluster in cluster_pool:\n",
    "        for id in cluster.ids:\n",
    "            print (next(item['cluster'] for item in input_data if item[\"id\"] == id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27a5b91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ids = []\n",
    "doc_count = 0\n",
    "for clst in test_cluster_pool.clusterpool:\n",
    "    print (clst.ids)\n",
    "    doc_count = doc_count +len(clst.ids)\n",
    "    ids.append(clst.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a2e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffcd990",
   "metadata": {},
   "source": [
    "<b>Inspect individual documents in those clusters</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316bc19e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for id in ['23309595', '23236595', '23302375', '23250759', '23254816']:\n",
    "    print ('\\n\\n', next((item['title'], item['date'], 'actual cluster: ', item['cluster']) for item in input_data if item[\"id\"] == id))\n",
    "    print ('\\n The matched cscore is ', test_scores[id][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37019c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "cluster_size = list(test_times.keys())           \n",
    "clustering_time = list(test_times.values())       \n",
    "\n",
    "plt.plot(cluster_size,clustering_time)\n",
    "plt.title('Clustering time by cluster pool size')\n",
    "plt.xlabel('Clusterpool size')\n",
    "plt.ylabel('Clustering time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dabbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lang,\"#docs\",len(test_corpus.documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6ede41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testcorpus = pd.DataFrame(test_corpus.documents)\n",
    "df_testcorpus = df_testcorpus[:2500]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5102b107",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb6e7a0",
   "metadata": {},
   "source": [
    "Shuffle the base test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d877faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basecorpus = pd.DataFrame(base_corpus.documents)\n",
    "df_basecorpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da07e4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testcorpus.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdc2eff",
   "metadata": {},
   "source": [
    "Convert new document data to representations for matching (if there is none saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac8ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create appropriate text/token representations for the document set\n",
    "rep_df = get_base(df_testcorpus)\n",
    "rep_df = add_tokenized(rep_df)\n",
    "rep_df = add_lemmas(rep_df)\n",
    "rep_df = add_entities(rep_df)\n",
    "    \n",
    "#Generate the tf/idf vectors from the appropriate model\n",
    "docrep_dicts = get_tfidf(rep_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86a15ce",
   "metadata": {},
   "source": [
    "Keep them for posterity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5318cb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE THE TEST CLUSTER REPRESENTATIONS WITH PICKLE\n",
    "with open('saved_models/test_document_reps.pickle','wb') as f:\n",
    "    pickle.dump(docrep_dicts, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d76cba",
   "metadata": {},
   "source": [
    "Load the saved test corpus and shuffle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c82203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docrep_dicts= pd.read_pickle(\"saved_models/test_document_reps.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412e093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(docrep_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9174afe8",
   "metadata": {},
   "source": [
    "Get maximum c-cscore for candidates in the cluster pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b181d96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cscore_max(doc, cluster_pool):\n",
    "    cscores = {}\n",
    "    for ind, clust in enumerate(cluster_pool):\n",
    "        cscores[ind]=c_score(clust,doc)\n",
    "    mx_val = max(cscores.values())\n",
    "    mx_ind = max(cscores, key=cscores.get)\n",
    "\n",
    "    targ_clust = cluster_pool[mx_ind]\n",
    "    return (targ_clust, mx_val )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c503d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "#for doc in randomly shuffled documents:\n",
    "for rawdoc in df_testcorpus.sample(frac=1).itertuples():\n",
    "    t0 = time.time()\n",
    "    #Create representations for entire base training set.\n",
    "    rep_ = get_base(pd.DataFrame([rawdoc]))\n",
    "    rep_df = add_tokenized(rep_)\n",
    "    rep_df = add_lemmas(rep_df)\n",
    "    rep_df = add_entities(rep_df)\n",
    "    doc = get_tfidf(rep_df)[0]\n",
    "    \n",
    "    #Find the maximum cscore in cluster pool candidates and get the actual text from the rep\n",
    "    clust, score = get_cscore_max(doc, cluster_pool)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    doc_row = df_testcorpus.loc[df_testcorpus['id'] == doc['id']]\n",
    "    \n",
    "    #Look at two random elements from the matching cluster\n",
    "    clustdoc_ids = random.sample(clust['idset'],2)\n",
    "    \n",
    "    print (\"\\n\\nANCHOR DOC TITLE: \", doc_row['title'].values)\n",
    "    print (\"CLOSEST CLUSTER: \", clust['cluster'])\n",
    "    print (\"C-SCORE: \", score)\n",
    "    print (\"CLUSTER SAMPLES: \")\n",
    "    for id in clustdoc_ids:\n",
    "        base_row = df_basecorpus.loc[df_basecorpus['id'] == id]\n",
    "        print (id, base_row['title'].values)\n",
    "    print (\"CONVERT AND MATCH TIME: \", t1-t0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eventclustering",
   "language": "python",
   "name": "eventclustering"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
