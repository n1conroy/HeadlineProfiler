{"cells":[{"cell_type":"code","execution_count":1,"id":"4b4ba660","metadata":{"id":"4b4ba660","executionInfo":{"status":"ok","timestamp":1659755608219,"user_tz":240,"elapsed":9,"user":{"displayName":"Nadia Conroy","userId":"09687839967270010584"}}},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","source":["!pip install transformers\n","!pip install bert-tensorflow"],"metadata":{"id":"a32taqPsJl0A"},"id":"a32taqPsJl0A","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AfJ35OOCI_LA","executionInfo":{"status":"ok","timestamp":1659755738804,"user_tz":240,"elapsed":906,"user":{"displayName":"Nadia Conroy","userId":"09687839967270010584"}},"outputId":"b26c6971-bf7b-4de1-f105-74c121cde589"},"id":"AfJ35OOCI_LA","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":8,"id":"b3ee24bf","metadata":{"id":"b3ee24bf","executionInfo":{"status":"ok","timestamp":1659755740631,"user_tz":240,"elapsed":159,"user":{"displayName":"Nadia Conroy","userId":"09687839967270010584"}}},"outputs":[],"source":["import sys\n","sys.path.insert(1, './drive/MyDrive/EventClustering/src')"]},{"cell_type":"code","execution_count":null,"id":"236db95b","metadata":{"id":"236db95b"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import utils\n","import corpus\n","import cluster\n","\n","pd.set_option('display.max_rows', None)\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.width', None)\n","pd.set_option('display.max_colwidth', -1)\n","\n","lang='eng'"]},{"cell_type":"code","execution_count":null,"id":"1c518447","metadata":{"id":"1c518447"},"outputs":[],"source":["lang = 'eng'\n","test_corpus = corpus.Corpus()\n","test_corpus.load_corpora(r\"./drive/MyDrive/EventClustering/dataset/dataset.dev.json\",\n","                           r\"./drive/MyDrive/EventClustering/dataset/clustering.dev.json\", set([lang]))"]},{"cell_type":"code","execution_count":null,"id":"e509e8c9","metadata":{"id":"e509e8c9"},"outputs":[],"source":["df = pd.DataFrame(test_corpus.documents)"]},{"cell_type":"code","execution_count":null,"id":"2100ab4e","metadata":{"id":"2100ab4e"},"outputs":[],"source":["token_corpus = np.array(df['text'].apply(lambda x: utils.preprocess_text(x)))\n"]},{"cell_type":"code","execution_count":null,"id":"dc09170e","metadata":{"id":"dc09170e"},"outputs":[],"source":["print (token_corpus)"]},{"cell_type":"code","execution_count":null,"id":"e2584bf3","metadata":{"id":"e2584bf3"},"outputs":[],"source":["lemma_corpus = np.array(df['text'].apply(lambda x: utils.get_lemma(x)))\n"]},{"cell_type":"code","execution_count":null,"id":"2274695b","metadata":{"id":"2274695b"},"outputs":[],"source":["entity_corpus = np.array(df['text'].apply(lambda x: utils.get_entity(x)))\n"]},{"cell_type":"code","execution_count":null,"id":"fc03e47a","metadata":{"id":"fc03e47a"},"outputs":[],"source":["print (len(lemma_corpus))"]},{"cell_type":"code","execution_count":null,"id":"4062bfa3","metadata":{"id":"4062bfa3"},"outputs":[],"source":["print (len(entity_corpus))"]},{"cell_type":"code","execution_count":null,"id":"4e235713","metadata":{"id":"4e235713"},"outputs":[],"source":["ent_jn = list(map(' '.join, entity_corpus))"]},{"cell_type":"code","execution_count":null,"id":"9a3e787d","metadata":{"id":"9a3e787d"},"outputs":[],"source":["print (result[5])"]},{"cell_type":"markdown","id":"2d053e6c","metadata":{"id":"2d053e6c"},"source":["Output the vocabularies of all the retained tfidf models"]},{"cell_type":"code","execution_count":null,"id":"2a49a7d9","metadata":{"id":"2a49a7d9"},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","import pickle\n","\n","#vectorizer = CountVectorizer(decode_error=\"replace\")\n","vectorizer= TfidfVectorizer(input='content', encoding='latin1', decode_error='strict', lowercase=True,  analyzer='word', stop_words='english', ngram_range=(1, 3), max_df=1.0, min_df=3, max_features=None,  binary=False, norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)\n","\n","tokvec_train = vectorizer.fit_transform(token_corpus)\n","pickle.dump(vectorizer.vocabulary_,open(\"models/token_feature.pkl\",\"wb\"))\n","\n","lemmavec_train = vectorizer.fit_transform(lemma_corpus)\n","pickle.dump(vectorizer.vocabulary_,open(\"modlels/lemma_feature.pkl\",\"wb\"))\n","\n","entityvec_train = vectorizer.fit_transform(ent_jn)\n","pickle.dump(vectorizer.vocabulary_,open(\"models/entity_feature.pkl\",\"wb\"))\n"]},{"cell_type":"code","execution_count":null,"id":"135182c1","metadata":{"scrolled":true,"id":"135182c1"},"outputs":[],"source":["d1 = (df.iloc[11])\n","d2 = (df.iloc[90])\n","d3 = (df.iloc[91])\n","d4 = (df.iloc[99])\n","d5 = (df.iloc[100])\n","d6 = (df.iloc[101])\n","d7 = (df.iloc[102])\n","d8 = (df.iloc[103])\n","d9 = (df.iloc[104])\n","d10 = (df.iloc[105])\n","\n","\n","d11 = (df.iloc[298])\n","d12 = (df.iloc[166])"]},{"cell_type":"code","execution_count":null,"id":"d37cfa13","metadata":{"id":"d37cfa13"},"outputs":[],"source":["print (d1.cluster)\n","print (d2.cluster)\n","print (d3.cluster)\n","print (d4.cluster)\n","print (d5.cluster)\n","\n","print (d7.cluster)\n","print (d8.cluster)\n","print (d9.cluster)\n","print (d10.cluster)\n","print (d11.cluster)\n","print (d12.cluster)\n","\n","print (d6.cluster)"]},{"cell_type":"code","execution_count":null,"id":"26977255","metadata":{"id":"26977255"},"outputs":[],"source":["doc1 = corpus.Document(d1)\n","pool1 = cluster.Cluster(doc1)\n","doc2 = corpus.Document(d2)\n","doc3 = corpus.Document(d3)\n","doc4 = corpus.Document(d4)\n","doc5 = corpus.Document(d5)\n","pool2 = cluster.Cluster(doc5)\n","\n","doc7 = corpus.Document(d7)\n","doc8 = corpus.Document(d8)\n","doc9 = corpus.Document(d9)\n","doc10 = corpus.Document(d10)\n","doc11 = corpus.Document(d11)\n","doc12 = corpus.Document(d12)\n","doc6 = corpus.Document(d6)\n"]},{"cell_type":"code","execution_count":null,"id":"393485b2","metadata":{"id":"393485b2"},"outputs":[],"source":["print ('\\nDOC1\\n', doc1)\n","print ('\\nDOC2\\n', doc2)"]},{"cell_type":"code","execution_count":null,"id":"06777a50","metadata":{"id":"06777a50"},"outputs":[],"source":["print (np.nonzero(doc1.reprs['body'])[1])\n","print (np.nonzero(doc2.reprs['body'])[1])\n","print (np.nonzero(doc3.reprs['body'])[1])\n","print (np.nonzero(doc4.reprs['body'])[1])\n","print (np.nonzero(doc5.reprs['body'])[1])\n","print (np.nonzero(doc6.reprs['body'])[1])\n","print (np.nonzero(doc7.reprs['body'])[1])"]},{"cell_type":"code","execution_count":null,"id":"14508099","metadata":{"id":"14508099"},"outputs":[],"source":["print ('Intersection of 1 and 2 ', np.intersect1d(np.nonzero(doc1.reprs['body'])[1], np.nonzero(doc2.reprs['body'])[1]))\n","print ('Intersection of 1 and 3 ', np.intersect1d(np.nonzero(doc1.reprs['body'])[1], np.nonzero(doc3.reprs['body'])[1]))\n","print ('Intersection of 2 and 3 ', np.intersect1d(np.nonzero(doc2.reprs['body'])[1], np.nonzero(doc3.reprs['body'])[1]))\n","print ('Intersection of 1 and 4 ', np.intersect1d(np.nonzero(doc1.reprs['body'])[1], np.nonzero(doc4.reprs['body'])[1]))\n","print ('Intersection of 2 and 5 ', np.intersect1d(np.nonzero(doc2.reprs['body'])[1], np.nonzero(doc5.reprs['body'])[1]))\n","print ('Intersection of 3 and 6 ', np.intersect1d(np.nonzero(doc3.reprs['body'])[1], np.nonzero(doc6.reprs['body'])[1]))"]},{"cell_type":"code","execution_count":null,"id":"c87d6201","metadata":{"id":"c87d6201"},"outputs":[],"source":["print (d1.title)\n","print (d1.text)\n","print (d1.cluster)\n","\n","print ('\\n',d2.title)\n","print (d2.text)\n","print (d2.cluster)\n","\n","print ('\\n',d3.title)\n","print (d3.text)\n","print (d3.cluster)\n","\n","print ('\\n',d4.title)\n","print (d4.text)\n","print (d4.cluster)\n","\n","print ('\\n',d5.title)\n","print (d5.text)\n","print (d5.cluster)\n","\n","print ('\\n',d6.title)\n","print (d6.text)\n","print (d6.cluster)\n","\n","print ('\\n',d7.title)\n","print (d7.text)\n","print (d7.cluster)"]},{"cell_type":"code","execution_count":null,"id":"3ad57175","metadata":{"id":"3ad57175"},"outputs":[],"source":["reps1 = utils.sim_reps_dc(doc1, pool1)\n","reps2 = utils.sim_reps_dc(doc2, pool1)\n","reps3 = utils.sim_reps_dc(doc3, pool1)\n","reps4 = utils.sim_reps_dc(doc4, pool1)\n","\n","reps5 = utils.sim_reps_dc(doc5, pool2)\n","reps7 = utils.sim_reps_dc(doc7, pool2)\n","reps8 = utils.sim_reps_dc(doc8, pool2)\n","reps9 = utils.sim_reps_dc(doc9, pool2)\n","\n","reps10 = utils.sim_reps_dc(doc10, pool2)\n","reps11 = utils.sim_reps_dc(doc11, pool1)\n","reps12 = utils.sim_reps_dc(doc12, pool2)\n","\n","reps6 = utils.sim_reps_dc(doc11, pool1)"]},{"cell_type":"code","execution_count":null,"id":"be8ac741","metadata":{"scrolled":true,"id":"be8ac741"},"outputs":[],"source":["print ('4 similar')\n","print (reps1,'\\n', reps2, '\\n', reps3, '\\n', reps4, '\\n')\n","\n","print ('4 similar')\n","print (reps5,'\\n', reps7, '\\n', reps8, '\\n', reps9, '\\n')\n","\n","print ('4 different')\n","print (reps6, '\\n', reps10, '\\n', reps11, '\\n', reps12)"]},{"cell_type":"code","execution_count":null,"id":"ea8bd96e","metadata":{"id":"ea8bd96e"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"id":"ad0863da","metadata":{"id":"ad0863da"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"id":"d6d9ef95","metadata":{"id":"d6d9ef95"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"eventclustering","language":"python","name":"eventclustering"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"name":"train_tfidfmodels.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":5}